{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding\n",
    "\n",
    "The main scope of the project is to program an advanced version of lane finding using camera calibration to remove distortion, apply diverse technique to isolate the lane marks and warp to have a \"bird's-eye view\" of the street.\n",
    "\n",
    "### Goals\n",
    "\n",
    "- Compute camera calibration matrix and distortion cohefficients using given chessboard images\n",
    "- Apply correction for distortion\n",
    "- Use color transformation, gradients and other techniques to create thresholded binary images\n",
    "- Create a \"bird-eye view\" of the image trhough perspective transformation\n",
    "- Find lane pixels and fit to determine lane boundaries\n",
    "- Calculate the curvature of the lane and the vehicole position\n",
    "- Project (unwrap) the detected lane boundaries back to the original image\n",
    "- Display lane boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera calibration\n",
    "Camera calibration using OpenCV function.\n",
    "The camera_calibration method takes in input 4 parameters, namely:\n",
    "- *pathre* : a path where calibration images are stored with a regular expression to filter the files to use\n",
    "- *nx* : number of reference point over the x axis\n",
    "- *ny* : number of reference point over the y axis\n",
    "- *save_calib* : if True a picle file named calibration_data.p will be created storing the matrix and distortion coefficients for later use ( reference: [CarND-Camera-Calibration](https://github.com/udacity/CarND-Camera-Calibration) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img, mtx, dist):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate camera calibration matrix and distortion coefficients.\n",
    "takes in input 4 parameters, namely:\n",
    "\n",
    "pathre : a path where calibration images are stored with a regular expression to filter the files to use\n",
    "nx : number of reference point over the x axis\n",
    "ny : number of reference point over the y axis\n",
    "save_calib : if True a picle file named calibration_data.p will be created storing the matrix \n",
    "and distortion coefficients for later use ( reference: CarND-Camera-Calibration )\n",
    "'''\n",
    "def camera_calibration(pathre=\"camera_cal/calibration*.jpg\", nx=8, ny=6, save_calib=True):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((ny*nx,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(pathre)\n",
    "    img_size = None\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        if img_size is None:\n",
    "            img_size = (img.shape[1], img.shape[0])\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "    if save_calib ==True:\n",
    "        dist_pickle = {}\n",
    "        dist_pickle[\"mtx\"] = mtx\n",
    "        dist_pickle[\"dist\"] = dist\n",
    "        pickle.dump( dist_pickle, open( \"calibration_data.p\", \"wb\" ) )\n",
    "        img = cv2.imread(images[0])\n",
    "        undistorted=undistort(img, mtx, dist)\n",
    "        cv2.imwrite('output_images/test_distorted.jpg', img)\n",
    "        cv2.imwrite('output_images/test_undistorted.jpg', undistorted)\n",
    "    return mtx, dist\n",
    "        \n",
    "mtx, dist = camera_calibration(pathre=\"camera_cal/calibration*.jpg\", nx=9, ny=6, save_calib=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline method definitions. \n",
    "Some methods could be simple recall to OpenCV methoe( e.g. undistort )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distortion correction\n",
    "Wrapper method to cv2.undistort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of thresholded binary images\n",
    "Here I start with the methods already used and developed during the lessons, so:\n",
    "- Color and gradient using the luminsity and saturation channel combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_gradient(img, s_thresh=(170, 255), sx_thresh=(20, 100), save_output=False):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    h_channel = hls[:,:,0]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    sobelxh = cv2.Sobel(h_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelxh = np.absolute(sobelxh) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobelh = np.uint8(255*abs_sobelx/np.max(abs_sobelxh))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold x gradient hue\n",
    "    sxbinaryh = np.zeros_like(scaled_sobelh)\n",
    "    sxbinaryh[(scaled_sobelh >= 50) & (scaled_sobelh <= 70)] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    color_binary = np.zeros_like(s_channel)\n",
    "    color_binary[(sxbinaryh==1) | (sxbinary == 1) | (s_binary==1)] =255\n",
    "#     vertices = np.array([[(570,445),(220,700),(1135,700),(730,445),(650,445),(995,680),(280,680),(630,445)]])\n",
    "#     color_binary_masked = region_of_interest(color_binary, vertices)\n",
    "    if save_output == True:\n",
    "        cv2.imwrite('output_images/color_grad_input.jpg', img)\n",
    "        cv2.imwrite('output_images/color_grad_out.jpg', color_binary)\n",
    "#         cv2.imwrite('output_images/color_grad_out_mask.jpg', color_binary_masked)\n",
    "    return color_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warp to create bird-eye view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp(img, save_output=False):\n",
    "    gray = img.copy()\n",
    "    src = np.float32([[600,465],[250,700],[1125,700],[720,465]])\n",
    "    dst = np.float32([[250,0],[250,img.shape[0]],[1060,img.shape[0]],[1060,0]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(img, M, (img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "#     vertices = np.array([[(250,0),(220,700),(1135,700),(730,445),(650,445),(995,680),(280,680),(630,445)]])\n",
    "#     color_binary_masked = region_of_interest(color_binary, vertices)\n",
    "    \n",
    "    if save_output == True:\n",
    "        cv2.imwrite('output_images/warp_input.jpg', img)\n",
    "        cv2.imwrite('output_images/warp_out.jpg', warped)\n",
    "    return warped, M, Minv\n",
    "\n",
    "def unwarp(img, Minv, save_output=False):\n",
    "    unwarped = cv2.warpPerspective(img, Minv, (img.shape[1],img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    if save_output == True:\n",
    "        cv2.imwrite('output_images/unwarp_input.jpg', img)\n",
    "        cv2.imwrite('output_images/unwarp_out.jpg', unwarped)\n",
    "    return unwarped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "# Choose the number of sliding windows\n",
    "nwindows = 9\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 100\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "\n",
    "lanewd_mt = 3.7\n",
    "lanewd_px = (1060-250) #/lanewd_mt\n",
    "\n",
    "def find_lane_pixels(binary_warped, save_output=False):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "#     detected_lanewd = (rightx_base-leftx_base)\n",
    "#     if detected_lanewd/lanewd_px < 0.8 or detected_lanewd/lanewd_px > 1.2:\n",
    "#         print(\"-\"*20)\n",
    "#         print(f\"!!!{detected_lanewd/lanewd_px} - {detected_lanewd} - {lanewd_px}\")\n",
    "#         print(leftx_base, rightx_base)\n",
    "#         if midpoint - leftx_base < lanewd_px*0.4 :\n",
    "#             print(\"mod_leftx\")\n",
    "#             leftx_base = np.argmax(histogram[:leftx_base-10])\n",
    "#         elif rightx_base - midpoint < lanewd_px*0.4 :\n",
    "#             rightx_base = np.argmax(histogram[rightx_base+10:])\n",
    "#         print(leftx_base, rightx_base)\n",
    "#         print(\"-\"*20)\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current -margin  # Update this\n",
    "        win_xleft_high = leftx_current + margin  # Update this\n",
    "        win_xright_low = rightx_current - margin  # Update this\n",
    "        win_xright_high = rightx_current + margin  # Update this\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "#         cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "#         (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "#         cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "#         (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &(nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    if save_output == True:\n",
    "        cv2.imwrite('output_images/findlanes_input.jpg', binary_warped)\n",
    "        cv2.imwrite('output_images/findlanes_out.jpg', out_img)\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def fit_polynomial(binary_warped, save_output=False):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped, save_output=save_output)\n",
    "\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "#     plt.plot(left_fitx, ploty, color='yellow')\n",
    "#     plt.plot(right_fitx, ploty, color='red')\n",
    "    window_img = np.zeros_like(out_img)\n",
    "\n",
    "    left_line_window = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    right_line_window = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    lane_pts=np.hstack((left_line_window, right_line_window))\n",
    "    cv2.fillPoly(window_img, np.int_([lane_pts]), (0,255, 0))\n",
    "    out_img = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    if save_output == True:\n",
    "        cv2.imwrite('output_images/fit_polynomial_input.jpg', binary_warped)\n",
    "        cv2.imwrite('output_images/fit_polynomial_out.jpg', out_img)\n",
    "    return out_img, left_fit, right_fit, left_fitx, right_fitx\n",
    "\n",
    "# out_img = fit_polynomial(cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY))\n",
    "# plt.imshow(cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poly(img_shape, leftx, lefty, rightx, righty, prevleft_fit, prevright_fit):\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    if prevleft_fit.shape[0]>1:\n",
    "        i0=np.max([0, prevleft_fit.shape[0]-7])\n",
    "        tmp = np.append(prevleft_fit[i0:-1], left_fit).reshape(-1,3)\n",
    "        left_fit = np.mean(tmp, axis=0)\n",
    "    if prevright_fit.shape[0]>1:\n",
    "        i0=np.max([0, prevright_fit.shape[0]-7])\n",
    "        tmp = np.append(prevright_fit[i0:-1], right_fit).reshape(-1,3)\n",
    "        right_fit = np.mean(tmp, axis=0)\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    return left_fitx, right_fitx, ploty, left_fit, right_fit\n",
    "\n",
    "def search_around_poly(binary_warped, prevleft_fit, prevright_fit, save_output=False):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    if prevleft_fit is None or prevright_fit is None:\n",
    "        return fit_polynomial(binary_warped, save_output=save_output)\n",
    "    left_fit = prevleft_fit[-1]\n",
    "    right_fit = prevright_fit[-1]\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    detected_lanewd = (np.mean(rightx)-np.mean(leftx))\n",
    "    if detected_lanewd/lanewd_px < 0.8 or detected_lanewd/lanewd_px > 1.2 or \\\n",
    "        len(leftx)==0 or len(lefty)==0 or len(rightx)==0 or len(righty)==0:\n",
    "        return fit_polynomial(binary_warped, save_output=save_output)\n",
    "    left_fitx, right_fitx, ploty, left_fit, right_fit = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty, \n",
    "                                                                 prevleft_fit, prevright_fit)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    \n",
    "    left_line_window = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    right_line_window = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    \n",
    "    \n",
    "    lane_pts=np.hstack((left_line_window, right_line_window))\n",
    "    \n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([lane_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "#     plt.plot(left_fitx, ploty, color='yellow')\n",
    "#     plt.plot(right_fitx, ploty, color='yellow')\n",
    "    ## End visualization steps ##\n",
    "    if save_output == True:\n",
    "        cv2.imwrite('output_images/search_around_poly_input.jpg', binary_warped)\n",
    "        cv2.imwrite('output_images/search_around_poly_out.jpg', result)\n",
    "    return result, left_fit, right_fit, left_fitx, right_fitx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevleft_fit=None\n",
    "prevright_fit=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature(img_shape, leftx, rightx, xm_per_pix=3.7/700, ym_per_pix = 30/720):\n",
    "    ploty = np.linspace(0, img_shape[0] - 1, num=img_shape[0])\n",
    "    \n",
    "    rleftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    rrightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    \n",
    "    # Fit a second order polynomial to pixel positions in each lane line\n",
    "    rleft_fit = np.polyfit(ploty, rleftx, 2)\n",
    "    rleft_fitx = rleft_fit[0]*ploty**2 + rleft_fit[1]*ploty + rleft_fit[2]\n",
    "    rright_fit = np.polyfit(ploty, rrightx, 2)\n",
    "    rright_fitx = rright_fit[0]*ploty**2 + rright_fit[1]*ploty + rright_fit[2]\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    y_eval = np.max(ploty)\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, rleftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rrightx*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    # Now our radius of curvature is in meters\n",
    "    return (left_curverad, right_curverad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_offset(img_shape, leftx, rightx, xm_per_pix=3.7/700):\n",
    "    ## Image mid horizontal position \n",
    "    midpoint = img_shape[1]//2\n",
    "        \n",
    "    ## Car position with respect to the lane\n",
    "    car_position = (leftx[-1] + rightx[-1])//2\n",
    "    \n",
    "    ## Horizontal car offset \n",
    "    offsetx = (midpoint - car_position) * xm_per_pix\n",
    "\n",
    "    return offsetx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_info(img, left_curverad, right_curverad, offset):    \n",
    "    out_img = img.copy()\n",
    "    cv2.putText(out_img, 'Left lane curvature: {:.2f} m'.format(left_curverad), \n",
    "                (60, 60), cv2.FONT_HERSHEY_COMPLEX, 1.5, (255,255,255), 5)\n",
    "    cv2.putText(out_img, 'Right lane curvature: {:.2f} m'.format(right_curverad), \n",
    "                (60, 110), cv2.FONT_HERSHEY_COMPLEX, 1.5, (255,255,255), 5)\n",
    "    \n",
    "    # Display car offset\n",
    "    cv2.putText(out_img, 'Car offset: {:.2f} m'.format(offset), \n",
    "                (60, 160), cv2.FONT_HERSHEY_COMPLEX, 1.5, (255,255,255), 5)\n",
    "    \n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_output=True\n",
    "def pipeline(image):\n",
    "    global prevleft_fit, prevright_fit\n",
    "    undistorted = undistort(image, mtx, dist)\n",
    "    grad = color_gradient(undistorted, s_thresh=(170, 255), sx_thresh=(35, 95), save_output=save_output)\n",
    "    warped,_, Minv = warp(grad, save_output=save_output)\n",
    "    out_img, left_fit, right_fit, left_x, right_x = search_around_poly(warped,\n",
    "                                                                       prevleft_fit, prevright_fit, save_output=save_output)\n",
    "    if prevleft_fit is None:\n",
    "        prevleft_fit = []\n",
    "    \n",
    "    prevleft_fit = np.append(prevleft_fit, left_fit).reshape(-1,3)\n",
    "    \n",
    "    if prevright_fit is None:\n",
    "        prevright_fit = []\n",
    "    prevright_fit = np.append(prevright_fit, right_fit).reshape(-1,3)\n",
    "        \n",
    "    left_curverad, right_curverad = measure_curvature(warped.shape, left_x, right_x, xm_per_pix=3.7/lanewd_px, ym_per_pix = 30/warped.shape[0])\n",
    "    offset = measure_offset(warped.shape, left_x, right_x, xm_per_pix=3.7/lanewd_px)\n",
    "    newwarp = unwarp(out_img, Minv) #cv2.warpPerspective(warped, Minv, (image.shape[1], image.shape[0])) \n",
    "    result = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "    resinfo= display_info(result, left_curverad, right_curverad, offset)\n",
    "    return resinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "prevleft_fit=None\n",
    "prevright_fit=None\n",
    "image = mpimg.imread(\"test_images/test1.jpg\")\n",
    "t = pipeline(image)\n",
    "t2 = pipeline(image)\n",
    "t2 = pipeline(image)\n",
    "t2 = pipeline(image)\n",
    "cv2.imwrite('output_images/pipeline_input.jpg', image)\n",
    "cv2.imwrite('output_images/firstrun_out.jpg', t)\n",
    "cv2.imwrite('output_images/secondrun_out.jpg', t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 3/1260 [00:00<01:09, 18.18it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_images/project_out.mp4.\n",
      "Moviepy - Writing video output_images/project_out.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_images/project_out.mp4\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "prevleft_fit=None\n",
    "prevright_fit=None\n",
    "save_output=False\n",
    "test_output = 'output_images/project_out.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "# test_output = \"tests/out_challenge_video.mp4\"\n",
    "# clip1 = VideoFileClip(\"challenge_video.mp4\").subclip(0,5)\n",
    "\n",
    "white_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(test_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   1%|          | 3/485 [00:00<00:26, 18.07it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_images/challenge_video.mp4.\n",
      "Moviepy - Writing video output_images/challenge_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_images/challenge_video.mp4\n",
      "Wall time: 40.9 s\n"
     ]
    }
   ],
   "source": [
    "prevleft_fit=None\n",
    "prevright_fit=None\n",
    "save_output=False\n",
    "test_output = 'output_images/challenge_video.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "\n",
    "# test_output = \"tests/out_challenge_video.mp4\"\n",
    "# clip1 = VideoFileClip(\"challenge_video.mp4\").subclip(0,5)\n",
    "\n",
    "white_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(test_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 3/1199 [00:00<01:08, 17.54it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_images/harder_challenge_video.mp4.\n",
      "Moviepy - Writing video output_images/harder_challenge_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_images/harder_challenge_video.mp4\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "prevleft_fit=None\n",
    "prevright_fit=None\n",
    "save_output=False\n",
    "test_output = 'output_images/harder_challenge_video.mp4'\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "\n",
    "# test_output = \"tests/out_challenge_video.mp4\"\n",
    "# clip1 = VideoFileClip(\"challenge_video.mp4\").subclip(0,5)\n",
    "\n",
    "white_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(test_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
